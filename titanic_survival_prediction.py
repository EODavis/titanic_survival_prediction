# -*- coding: utf-8 -*-
"""Titanic Survival Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FCLoVSl4PMkilXAPlv_jd1bZIMJp6VJX
"""

import pandas as pd
import seaborn as sns

# Load data directly
df = sns.load_dataset('titanic')

# Quick look
print(df.shape)
df.head()

# Drop columns we wonâ€™t use
df = df.drop(columns=['deck', 'embark_town', 'alive'])

# Drop rows with missing values
df = df.dropna()

# Encode categorical variables
df = pd.get_dummies(df, drop_first=True)

# Features and target
X = df.drop('survived', axis=1)
y = df['survived']

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Train
tree = DecisionTreeClassifier(max_depth=4, random_state=42)
tree.fit(X_train, y_train)

# Predict & evaluate
y_pred = tree.predict(X_test)
print(classification_report(y_test, y_pred))

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(20,10))
plot_tree(tree, feature_names=X.columns, class_names=["Not Survived", "Survived"], filled=True)
plt.show()

from sklearn.ensemble import RandomForestClassifier

# Initialize and train
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Predict & evaluate
y_pred_rf = rf.predict(X_test)
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_rf))

import matplotlib.pyplot as plt
import seaborn as sns

# Get feature importances
importances = rf.feature_importances_
features = X.columns
feat_imp = pd.Series(importances, index=features).sort_values(ascending=False)

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(x=feat_imp[:10], y=feat_imp.index[:10])
plt.title('Top 10 Feature Importances')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.tight_layout()
plt.show()

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# Define parameter grid
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

grid_search = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_grid=param_grid,
    cv=5,
    scoring='f1',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train, y_train)

print("Best Params:", grid_search.best_params_)
print("Best F1 Score:", grid_search.best_score_)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Final model with best params
final_rf = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42
)

final_rf.fit(X_train, y_train)
y_pred = final_rf.predict(X_test)

# Evaluation
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

import pickle
from sklearn.preprocessing import StandardScaler
best_model = final_rf
scaler = StandardScaler()
scaler.fit(X[['age', 'fare']])
# Save model
with open('model.pkl', 'wb') as f:
    pickle.dump(best_model, f)  # or whatever your final model is

# Save scaler
with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

# prompt: download the .pkl files from joblib

# from google.colab import files
# files.download('model.pkl')
# files.download('scaler.pkl')

import streamlit as st
import pickle
import numpy as np

# Load model and scaler
model = pickle.load(open("model.pkl", "rb"))
scaler = pickle.load(open("scaler.pkl", "rb"))

st.title("ðŸš¢ Titanic Survival Prediction")

# Collect input
age = st.slider("Age", 0, 100, 30)
fare = st.slider("Fare", 0.0, 600.0, 32.2)
adult_male = st.selectbox("Adult Male?", ["Yes", "No"])
adult_male = 1 if adult_male == "Yes" else 0

# Scale input
input_data = pd.DataFrame([[age, fare, ]],
                          columns=['age', 'fare',])
input_scaled = scaler.transform(input_data)

# Predict
if st.button("Predict"):
    prediction = model.predict(input_scaled)[0]
    prob = model.predict_proba(input_scaled)[0][prediction]
    label = "Survived" if prediction == 0 else "Did not survive"
    st.success(f"Prediction: {label} ({prob * 100:.1f}% confidence)")

